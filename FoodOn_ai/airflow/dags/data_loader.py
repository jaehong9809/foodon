import os
import json
import pymysql
import pandas as pd
import requests
import logging
from PIL import Image
from io import BytesIO
from dotenv import load_dotenv
import os
import shutil

load_dotenv()
# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)


def generate_dataset_from_df(
    df,
    image_dir="/dataset/dataset/images",
    label_dir="/dataset/dataset/labels",
    conf_min=0.3,
    conf_max=0.99,
):
    os.makedirs(image_dir, exist_ok=True)
    os.makedirs(label_dir, exist_ok=True)

    for meal_id, group in df.groupby("meal_id"):
        image_url = group.iloc[0]["meal_image"]

        # í•„í„°ë§ ë¨¼ì € ìˆ˜í–‰
        filtered_rows = [
            row for _, row in group.iterrows()
            if conf_min <= row.get("confidence", 1.0) <= conf_max
        ]

        if not filtered_rows:
            logger.info(f"ğŸš« confidence ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë¼ë²¨ ì—†ìŒ: {meal_id}")
            continue  # ì´ë¯¸ì§€ ë° ë¼ë²¨ ëª¨ë‘ ì €ì¥í•˜ì§€ ì•ŠìŒ

        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        try:
            response = requests.get(image_url, timeout=5)
            image = Image.open(BytesIO(response.content)).convert("RGB")
            width, height = image.size
        except Exception as e:
            logger.warning(f"âš ï¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({meal_id}): {e}")
            continue

        # ì´ë¯¸ì§€ ì €ì¥
        image_path = os.path.join(image_dir, f"{meal_id}.jpg")
        image.save(image_path)
        logger.info(f"âœ… ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {image_path}")

        # ë¼ë²¨ ìƒì„±
        annotations = []
        for row in filtered_rows:
            abs_x = int(row["x"] * width)
            abs_y = int(row["y"] * height)
            abs_w = int(row["width"] * width)
            abs_h = int(row["height"] * height)
            annotations.append(
                {
                    "x": abs_x,
                    "y": abs_y,
                    "width": abs_w,
                    "height": abs_h,
                    "class_id": row["food_name"],
                }
            )

        label = {
            "image": f"{meal_id}.jpg",
            "width": width,
            "height": height,
            "annotations": annotations,
        }

        label_path = os.path.join(label_dir, f"{meal_id}.json")
        with open(label_path, "w", encoding="utf-8") as f:
            json.dump(label, f, ensure_ascii=False, indent=2)

        logger.info(f"ğŸ“„ ë¼ë²¨ ì €ì¥ ì™„ë£Œ: {label_path}")




def load_data_from_db(min_count=10):
    logger.info("ğŸ“¦ DB ì—°ê²° ì‹œë„ ì¤‘...")

    conn = pymysql.connect(
        host=os.getenv("DB_HOST"),
        port=int(os.getenv("DB_PORT")),
        user=os.getenv("DB_USER"),
        password=os.getenv("DB_PASSWORD"),
        database=os.getenv("DB_NAME"),
        charset=os.getenv("DB_CHARSET"),
        ssl_disabled=True,
    )

    try:
        with conn.cursor() as cursor:
            cursor.execute("SELECT COUNT(*) FROM meals")
            count = cursor.fetchone()[0]
            logger.info(f"ğŸ“Š í˜„ì¬ meals ìˆ˜: {count}ê±´")

        if count < min_count:
            logger.warning(f"âš ï¸ ë°ì´í„° ê±´ìˆ˜ : {count}")
            logger.warning(f"âš ï¸ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì¤‘ë‹¨ (ê¸°ì¤€: {min_count})")
            return None

        logger.info("âœ… ì¶©ë¶„í•œ ë°ì´í„° í™•ë³´, ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")

        query = """
                SELECT 
                    m.meal_id AS meal_id,
                    m.meal_image,
                    mi.food_name,
                    p.x, p.y, p.width, p.height, p.confidence
                FROM meals m
                JOIN meal_items mi ON m.meal_id = mi.meal_id
                JOIN positions p ON mi.meal_item_id = p.meal_item_id
                WHERE m.meal_time >= NOW() - INTERVAL 7 DAY
                ORDER BY m.meal_id
                LIMIT 10
        """
        df = pd.read_sql(query, conn)

        logger.info(f"ğŸ“¥ DBì—ì„œ {len(df)}ê°œì˜ ë¼ë²¨ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤")

        # ë°ì´í„°ì…‹ ìƒì„±
        generate_dataset_from_df(df)

        logger.info("ğŸ“‚ ì´ë¯¸ì§€ ë° ë¼ë²¨ íŒŒì¼ ì €ì¥ ì™„ë£Œ")
        return df

    except Exception as e:
        logger.error(f"âŒ DB ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

    finally:
        conn.close()
        logger.info("ğŸ”Œ DB ì—°ê²° ì¢…ë£Œ")

def delete_data():
    folder_path = "/dataset/dataset"

    if os.path.isdir(folder_path):
        shutil.rmtree(folder_path)
        print(f"ğŸ—‘ï¸ ì „ì²´ ì‚­ì œ ì™„ë£Œ: {folder_path}")
    else:
        print(f"âŒ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {folder_path}")    
