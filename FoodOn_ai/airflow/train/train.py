import os
import mlflow
import mlflow.pytorch
from .names_id import names, class_id_to_index
from .transform import get_transform
from .FoodDetectionDataset import FoodDetectionDataset
# MLflow ì„¤ì •

from torch.utils.data import Dataset
from PIL import Image, ImageOps
import torch
import json
import numpy as np
from pathlib import Path
import torchvision.transforms as T

from torchvision.models.detection import (
    fasterrcnn_resnet50_fpn,
    FasterRCNN_ResNet50_FPN_Weights,
)
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor

mlflow.set_tracking_uri("http://mlflow_server:5000")
mlflow.set_experiment("food_detection")


def create_model(num_classes: int = 68):
    weights = FasterRCNN_ResNet50_FPN_Weights.DEFAULT
    model = fasterrcnn_resnet50_fpn(weights=weights)

    # for param in model.backbone.body.parameters():
    #     param.requires_grad = False
    for name, param in model.backbone.body.named_parameters():
        if "layer3" in name or "layer4" in name:
            param.requires_grad = True

    in_features = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
    return model


import torch.optim as optim
from tqdm import tqdm


def train_one_epoch(model, data_loader, device, optimizer):
    model.train()
    total_loss = 0.0

    loop = tqdm(data_loader, desc="ğŸ”¥ Training", leave=False)
    for images, targets in loop:
        images = [img.to(device) for img in images]
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

        loss_dict = model(images, targets)
        losses = sum(loss for loss in loss_dict.values())

        optimizer.zero_grad()
        losses.backward()
        optimizer.step()

        total_loss += losses.item()

        # âœ… í˜„ì¬ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰(MB)ë„ ì¶œë ¥
        mem_allocated = torch.cuda.memory_allocated(device) / 1024**2
        loop.set_postfix(loss=losses.item(), gpu_mem=f"{mem_allocated:.1f}MB")

    return total_loss


from torchmetrics.detection.mean_ap import MeanAveragePrecision


@torch.no_grad()
def evaluate(model, data_loader, device):
    model.eval()
    metric = MeanAveragePrecision(iou_thresholds=[0.5])

    for images, targets in data_loader:
        images = [img.to(device) for img in images]
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]
        outputs = model(images)
        metric.update(preds=outputs, target=targets)

    return metric.compute()  # ì „ì²´ ê²°ê³¼ í†µì§¸ë¡œ ë°˜í™˜


full_dataset = FoodDetectionDataset("./dataset", transforms=get_transform(train=True))

# 80:20 ë¹„ìœ¨ë¡œ train/val ë‚˜ëˆ„ê¸°
train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_dataset, val_dataset = random_split(
    full_dataset,
    [train_size, val_size],
    generator=torch.Generator().manual_seed(42),  # ì¬í˜„ ê°€ëŠ¥í•˜ê²Œ ì‹œë“œ ê³ ì •
)

# ê²€ì¦ìš© transform ë”°ë¡œ ì§€ì •
val_dataset.dataset.transforms = get_transform(train=False)

# DataLoader ì„¤ì •
train_loader = DataLoader(
    train_dataset,
    batch_size=16,
    shuffle=True,
    num_workers=1,
    pin_memory=True,
    collate_fn=lambda x: tuple(zip(*x)),
)

val_loader = DataLoader(
    val_dataset,
    batch_size=16,
    shuffle=False,
    num_workers=1,
    pin_memory=True,
    collate_fn=lambda x: tuple(zip(*x)),
)

import os
import torch
import time

# ëª¨ë¸ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = create_model(num_classes=68)
model.to(device)

# ğŸ”½ ì´ì–´ì„œ í•™ìŠµì„ ìœ„í•œ ê°€ì¤‘ì¹˜ ë¡œë“œ
base_dir = os.path.dirname(os.path.abspath(__file__))
model_path = os.path.join(base_dir, "best_model_0513.pth")
if os.path.exists(model_path):
    model.load_state_dict(torch.load(model_path))
    print(f"âœ… ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤: {model_path}")
else:
    print("âš ï¸ ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ëª¨ë¸ë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")

optimizer = optim.SGD(
    [p for p in model.parameters() if p.requires_grad],
    lr=0.005,
    momentum=0.9,
    weight_decay=0.0005,
)

# ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬
#save_dir = "weights5"
#os.makedirs(save_dir, exist_ok=True)

# Early Stopping ì„¤ì •
patience = 5  # ê°œì„  ì—†ì„ ë•Œ ëª‡ ë²ˆ ì°¸ì„ì§€
best_val_map = 0.0
patience_counter = 0
num_epochs = 10  # ìµœëŒ€ ì—í­ ìˆ˜

with mlflow.start_run(run_name="fasterrcnn_training"):
    mlflow.log_param("num_epochs", num_epochs)
    mlflow.log_param("optimizer", "SGD")
    mlflow.log_param("learning_rate", 0.005)

    total_start_time = time.time()
    for epoch in range(num_epochs):
        start_time = time.time()

        train_loss = train_one_epoch(model, train_loader, device, optimizer)
        result = evaluate(model, val_loader, device)
        val_map = result["map_50"].item()

        elapsed = time.time() - start_time

        print(
            f"[Epoch {epoch+1}] ğŸ‹ï¸ Train Loss: {train_loss:.4f} | ğŸ“Š Val mAP@0.5: {val_map:.4f} | â± Time: {elapsed:.2f}s"
        )
        mlflow.log_metric("val_map@0.5", val_map, step=epoch)
        mlflow.log_metric("train_loss", train_loss, step=epoch)

        if val_map > best_val_map:
            best_val_map = val_map
            patience_counter = 0
            #save_path = os.path.join(save_dir, "best_model.pth")
            #torch.save(model.state_dict(), save_path)
            print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ (val mAP ê°ì§€): {save_path}")

            # MLflow ëª¨ë¸ ì €ì¥
            mlflow.pytorch.log_model(model, "model")

        else:
            patience_counter += 1
            print(f"â³ patience: {patience_counter}/{patience}")

            if patience_counter >= patience:
                print(f"ğŸš© Early stopping: {epoch+1} epoch ì´í›„ val mAP ê°ì§€ ì—†ìŒ")
                break

    total_elapsed = time.time() - total_start_time
    print(f"\nâ± ì „ì²´ í•™ìŠµ ì‹œê°„: {total_elapsed:.2f}ì´ˆ ({total_elapsed/60:.2f}ë¶„)")
