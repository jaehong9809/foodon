from fastapi import APIRouter
from ..schemas.request import RequestSchema
from ..schemas.response import ResponseSchema
from ..service.preprocessing import load_image_from_url, preprocess
from ..service.postprocessing import postprocess
from ..core.model_state import model
import torch
import time
from PIL import Image
router = APIRouter()

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


@router.post("/detect", response_model=ResponseSchema)
async def detect_objects(request: RequestSchema):
    total_start = time.time()
    # ì´ë¯¸ì§€ ë¡œë”©
    t0 = time.time()
    image = load_image_from_url(request.url)
    t1 = time.time()
    print(f"ğŸ•’ ì´ë¯¸ì§€ ë¡œë”© ì‹œê°„: {t1 - t0:.4f}ì´ˆ")

    width, height = image.size

    # ì „ì²˜ë¦¬
    t2 = time.time()
    img_tensor = preprocess(image, device)
    t3 = time.time()
    print(f"ğŸ§¹ ì „ì²˜ë¦¬ ì‹œê°„: {t3 - t2:.4f}ì´ˆ")

    # ì¶”ë¡ 
    t4 = time.time()
    with torch.inference_mode():
        prediction = model(img_tensor)[0]
    t5 = time.time()
    print(f"ğŸ¤– ì¶”ë¡  ì‹œê°„: {t5 - t4:.4f}ì´ˆ")

    # í›„ì²˜ë¦¬
    t6 = time.time()
    food_items = postprocess(prediction, width, height, model_input_size=640)
    t7 = time.time()
    print(f"ğŸ” í›„ì²˜ë¦¬ ì‹œê°„: {t7 - t6:.4f}ì´ˆ")

    total_end = time.time()
    print(f"â±ï¸ ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {total_end - total_start:.4f}ì´ˆ")

    return ResponseSchema(food=food_items)

from fastapi import UploadFile, File

@router.post("/detect2", response_model=ResponseSchema)
async def detect_objects_2(file: UploadFile = File(...)):
    total_start = time.time()
    
    # ì´ë¯¸ì§€ ë¡œë”©
    t0 = time.time()
    image = Image.open(file.file).convert("RGB")  # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
    t1 = time.time()
    print(f"ğŸ•’ ëª¨ë¸ ë¡œë“œ, ì´ë¯¸ì§€ ë¡œë”© ì‹œê°„: {t1 - t0:.4f}ì´ˆ")

    width, height = image.size

    # ì „ì²˜ë¦¬
    t2 = time.time()
    img_tensor = preprocess(image, device)
    t3 = time.time()
    print(f"ğŸ§¹ ì „ì²˜ë¦¬ ì‹œê°„: {t3 - t2:.4f}ì´ˆ")

    # ì¶”ë¡ 
    t4 = time.time()
    with torch.inference_mode():
        prediction = model(img_tensor)[0]
    t5 = time.time()
    print(f"ğŸ¤– ì¶”ë¡  ì‹œê°„: {t5 - t4:.4f}ì´ˆ")

    # í›„ì²˜ë¦¬
    t6 = time.time()
    food_items = postprocess(prediction, width, height, model_input_size=640)
    t7 = time.time()
    print(f"ğŸ” í›„ì²˜ë¦¬ ì‹œê°„: {t7 - t6:.4f}ì´ˆ")

    total_end = time.time()
    print(f"â±ï¸ ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {total_end - total_start:.4f}ì´ˆ")

    return ResponseSchema(food=food_items)
